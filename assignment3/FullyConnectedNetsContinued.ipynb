{"cells":[{"cell_type":"code","execution_count":1,"id":"9d00f408","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d00f408","executionInfo":{"status":"ok","timestamp":1731034809271,"user_tz":480,"elapsed":1375,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"a26913d7-4aa0-4451-b900-76a39f990c26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/cse493g1/assignment3/cse493g1/datasets\n","/content/drive/My Drive/cse493g1/assignment3\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cse493g1/assignments/assignment3/'\n","FOLDERNAME = 'cse493g1/assignment3/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# This downloads the COCO dataset to your Drive\n","# if it doesn't already exist.\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/cse493g1/datasets/\n","!bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"markdown","id":"246afaf0","metadata":{"id":"246afaf0"},"source":["# Multi-Layer Fully Connected Network Part 2\n","In this exercise, you will extend your fully connected network from Assignment 2 with Dropout and Normalization Layers. First, you will copy and paste all the necessary parts from Assignment 2. Then you will re-train your model from A2 as a baseline. Next, you will complete the batchnorm and dropout notebook, and then return to this notebook and create an improved model using dropout and normalization."]},{"cell_type":"code","execution_count":2,"id":"324aef21","metadata":{"tags":["pdf-ignore"],"colab":{"base_uri":"https://localhost:8080/"},"id":"324aef21","executionInfo":{"status":"ok","timestamp":1731034809490,"user_tz":480,"elapsed":221,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"30b9b266-6475-437c-9318-94cc0643f93d"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========== You can safely ignore the message below if you are NOT working on ConvolutionalNetworks.ipynb ===========\n","\tYou will need to compile a Cython extension for a portion of this assignment.\n","\tThe instructions to do this will be given in a section of the notebook below.\n"]}],"source":["# Setup cell.\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from cse493g1.classifiers.fc_net import *\n","from cse493g1.data_utils import get_CIFAR10_data\n","from cse493g1.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n","from cse493g1.solver import Solver\n","\n","%matplotlib inline\n","plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # Set default size of plots.\n","plt.rcParams[\"image.interpolation\"] = \"nearest\"\n","plt.rcParams[\"image.cmap\"] = \"gray\"\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","def rel_error(x, y):\n","    \"\"\"Returns relative error.\"\"\"\n","    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"]},{"cell_type":"code","execution_count":3,"id":"182448da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"182448da","executionInfo":{"status":"ok","timestamp":1731034815246,"user_tz":480,"elapsed":5758,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"213e2db4-f39f-4652-93d5-c8200bd5eac8"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: (49000, 3, 32, 32)\n","y_train: (49000,)\n","X_val: (1000, 3, 32, 32)\n","y_val: (1000,)\n","X_test: (1000, 3, 32, 32)\n","y_test: (1000,)\n"]}],"source":["# Load the (preprocessed) CIFAR-10 data.\n","data = get_CIFAR10_data()\n","for k, v in list(data.items()):\n","    print(f\"{k}: {v.shape}\")"]},{"cell_type":"markdown","id":"2a3acb10","metadata":{"id":"2a3acb10"},"source":["# Copy necessary parts from A2.\n","Fill in the following functions by copying and pasting your answers from A2:\n","`affine_forward` in `cse493g1/layers.py`\n","`affine_backward` in `cse493g1/layers.py`\n","`relu_forward` in `cse493g1/layers.py`\n","`relu_backward` in `cse493g1/layers.py`\n","`softmax_loss` in `cse493g1/layers.py`\n","`sgd_momentum` in `cse493g1/optim.py`\n","`rmsprop` in `cse493g1/optim.py`\n","`adam` in `cse493g1/optim.py`\n","\n"]},{"cell_type":"markdown","id":"ce64d653","metadata":{"id":"ce64d653"},"source":["# Train baseline model from A2\n","Copy and Paste your `FullyConnectedNet` model from `cse493g1/classifiers/fc_net.py` in Assignment 2 into `FullyConnectedNetBasic` in the file `cse493g1/classifiers/fc_net.py` in this assignment. Use the best hyperparms that you found from the previous assignment to train this model. Call this model `best_model_basic`"]},{"cell_type":"code","execution_count":4,"id":"3ab6d0f1","metadata":{"id":"3ab6d0f1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731034947167,"user_tz":480,"elapsed":131922,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"2bf0919a-a043-4cdf-aebf-b39a02e5fa8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["lr: 0.00019810883630280872, reg: 0.0051124710979752646, weight_scale: 0.011387564370987585\n","(Iteration 1 / 3675) loss: 2.426512\n","(Epoch 0 / 15) train acc: 0.163000; val_acc: 0.172000\n","(Iteration 101 / 3675) loss: 1.646942\n","(Iteration 201 / 3675) loss: 1.622002\n","(Epoch 1 / 15) train acc: 0.465000; val_acc: 0.475000\n","(Iteration 301 / 3675) loss: 1.751139\n","(Iteration 401 / 3675) loss: 1.353533\n","(Epoch 2 / 15) train acc: 0.509000; val_acc: 0.479000\n","(Iteration 501 / 3675) loss: 1.481615\n","(Iteration 601 / 3675) loss: 1.251106\n","(Iteration 701 / 3675) loss: 1.466859\n","(Epoch 3 / 15) train acc: 0.560000; val_acc: 0.509000\n","(Iteration 801 / 3675) loss: 1.455386\n","(Iteration 901 / 3675) loss: 1.361844\n","(Epoch 4 / 15) train acc: 0.562000; val_acc: 0.486000\n","(Iteration 1001 / 3675) loss: 1.276741\n","(Iteration 1101 / 3675) loss: 1.353588\n","(Iteration 1201 / 3675) loss: 1.298143\n","(Epoch 5 / 15) train acc: 0.560000; val_acc: 0.515000\n","(Iteration 1301 / 3675) loss: 1.248636\n","(Iteration 1401 / 3675) loss: 1.240691\n","(Epoch 6 / 15) train acc: 0.610000; val_acc: 0.502000\n","(Iteration 1501 / 3675) loss: 1.161556\n","(Iteration 1601 / 3675) loss: 1.121236\n","(Iteration 1701 / 3675) loss: 1.381143\n","(Epoch 7 / 15) train acc: 0.599000; val_acc: 0.507000\n","(Iteration 1801 / 3675) loss: 1.217902\n","(Iteration 1901 / 3675) loss: 1.133077\n","(Epoch 8 / 15) train acc: 0.640000; val_acc: 0.537000\n","(Iteration 2001 / 3675) loss: 1.112644\n","(Iteration 2101 / 3675) loss: 1.180011\n","(Iteration 2201 / 3675) loss: 1.211633\n","(Epoch 9 / 15) train acc: 0.613000; val_acc: 0.536000\n","(Iteration 2301 / 3675) loss: 1.151611\n","(Iteration 2401 / 3675) loss: 1.256100\n","(Epoch 10 / 15) train acc: 0.645000; val_acc: 0.528000\n","(Iteration 2501 / 3675) loss: 1.123917\n","(Iteration 2601 / 3675) loss: 1.132005\n","(Epoch 11 / 15) train acc: 0.669000; val_acc: 0.541000\n","(Iteration 2701 / 3675) loss: 1.139565\n","(Iteration 2801 / 3675) loss: 1.017943\n","(Iteration 2901 / 3675) loss: 1.141487\n","(Epoch 12 / 15) train acc: 0.661000; val_acc: 0.524000\n","(Iteration 3001 / 3675) loss: 1.063306\n","(Iteration 3101 / 3675) loss: 1.148321\n","(Epoch 13 / 15) train acc: 0.651000; val_acc: 0.526000\n","(Iteration 3201 / 3675) loss: 0.968495\n","(Iteration 3301 / 3675) loss: 1.081471\n","(Iteration 3401 / 3675) loss: 1.046040\n","(Epoch 14 / 15) train acc: 0.681000; val_acc: 0.532000\n","(Iteration 3501 / 3675) loss: 0.989430\n","(Iteration 3601 / 3675) loss: 0.991854\n","(Epoch 15 / 15) train acc: 0.681000; val_acc: 0.531000\n"]}],"source":["best_model_basic = None\n","\n","################################################################################\n","# TODO: Train the best FullyConnectedNetBasic that you can on CIFAR-10. Store your best model in  #\n","# the best_model_basic variable.                                                     #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","lr = 0.00019810883630280872\n","reg = 0.0051124710979752646\n","weight_scale = 0.011387564370987585\n","H1, H2 = 100, 100\n","print(f\"lr: {lr}, reg: {reg}, weight_scale: {weight_scale}\")\n","net = FullyConnectedNetBasic(hidden_dims=[H1, H2], reg=reg ,weight_scale=weight_scale,\n","  dtype=np.float64)\n","\n","solver = Solver(net, data,\n","                    update_rule='adam',\n","                    optim_config={\n","                      'learning_rate': lr,\n","                    },\n","                    lr_decay=0.95,\n","                    num_epochs=15, batch_size=200, print_every=100,\n","                    verbose = True)\n","solver.train()\n","y_val_pred = np.argmax(net.loss(data['X_val']), axis=1)\n","val_acc = (y_val_pred == data['y_val']).mean()\n","best_model_basic = net\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"markdown","id":"2f950845","metadata":{"id":"2f950845"},"source":["# Evaluate baseline model from A2\n","Evaluate above baseline model."]},{"cell_type":"code","execution_count":5,"id":"2c53bd31","metadata":{"id":"2c53bd31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731034947167,"user_tz":480,"elapsed":11,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"979a4c46-8ca7-4dd7-94a5-71001e3556b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation set accuracy:  0.541\n","Test set accuracy:  0.524\n"]}],"source":["y_test_pred = np.argmax(best_model_basic.loss(data['X_test']), axis=1)\n","y_val_pred = np.argmax(best_model_basic.loss(data['X_val']), axis=1)\n","print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n","print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"]},{"cell_type":"markdown","id":"c2f8f378","metadata":{"id":"c2f8f378"},"source":["# Train improved model\n","Design a new model in `FullyConnectedNetImproved` in the file `cse493g1/classifiers/fc_net.py`. You can start by having `FullyConnectedNetImproved` be the same design as `FullyConnectedNetBasic`. Next, complete the BatchNormoralization.ipynb and Dropout.ipynb notebooks. Then return to this notebook and complete `FullyConnectedNetImproved` by adding in batchnorm and dropout. Try to beat the accuracy of your baseline model! You may have to adjust your hyperparameters."]},{"cell_type":"code","execution_count":37,"id":"601dfcda","metadata":{"scrolled":false,"id":"601dfcda","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731037247252,"user_tz":480,"elapsed":149202,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"a9c43117-28a0-4d3d-9554-da822d7da007"},"outputs":[{"output_type":"stream","name":"stdout","text":["lr: 0.0012281088363028088, reg: 0.0011124710979752647, weight_scale: 0.011387564370987585\n","(Iteration 1 / 3675) loss: 2.331599\n","(Epoch 0 / 15) train acc: 0.176000; val_acc: 0.172000\n","(Iteration 101 / 3675) loss: 1.779805\n","(Iteration 201 / 3675) loss: 1.694969\n","(Epoch 1 / 15) train acc: 0.440000; val_acc: 0.448000\n","(Iteration 301 / 3675) loss: 1.696769\n","(Iteration 401 / 3675) loss: 1.651655\n","(Epoch 2 / 15) train acc: 0.441000; val_acc: 0.472000\n","(Iteration 501 / 3675) loss: 1.500860\n","(Iteration 601 / 3675) loss: 1.732796\n","(Iteration 701 / 3675) loss: 1.504536\n","(Epoch 3 / 15) train acc: 0.493000; val_acc: 0.481000\n","(Iteration 801 / 3675) loss: 1.687051\n","(Iteration 901 / 3675) loss: 1.443392\n","(Epoch 4 / 15) train acc: 0.494000; val_acc: 0.496000\n","(Iteration 1001 / 3675) loss: 1.534725\n","(Iteration 1101 / 3675) loss: 1.623322\n","(Iteration 1201 / 3675) loss: 1.501162\n","(Epoch 5 / 15) train acc: 0.540000; val_acc: 0.500000\n","(Iteration 1301 / 3675) loss: 1.501353\n","(Iteration 1401 / 3675) loss: 1.519748\n","(Epoch 6 / 15) train acc: 0.518000; val_acc: 0.514000\n","(Iteration 1501 / 3675) loss: 1.418003\n","(Iteration 1601 / 3675) loss: 1.458596\n","(Iteration 1701 / 3675) loss: 1.430819\n","(Epoch 7 / 15) train acc: 0.558000; val_acc: 0.524000\n","(Iteration 1801 / 3675) loss: 1.468894\n","(Iteration 1901 / 3675) loss: 1.436563\n","(Epoch 8 / 15) train acc: 0.545000; val_acc: 0.506000\n","(Iteration 2001 / 3675) loss: 1.478416\n","(Iteration 2101 / 3675) loss: 1.435246\n","(Iteration 2201 / 3675) loss: 1.372398\n","(Epoch 9 / 15) train acc: 0.593000; val_acc: 0.525000\n","(Iteration 2301 / 3675) loss: 1.392103\n","(Iteration 2401 / 3675) loss: 1.370348\n","(Epoch 10 / 15) train acc: 0.584000; val_acc: 0.529000\n","(Iteration 2501 / 3675) loss: 1.566360\n","(Iteration 2601 / 3675) loss: 1.210746\n","(Epoch 11 / 15) train acc: 0.593000; val_acc: 0.519000\n","(Iteration 2701 / 3675) loss: 1.455167\n","(Iteration 2801 / 3675) loss: 1.405203\n","(Iteration 2901 / 3675) loss: 1.516038\n","(Epoch 12 / 15) train acc: 0.596000; val_acc: 0.534000\n","(Iteration 3001 / 3675) loss: 1.368895\n","(Iteration 3101 / 3675) loss: 1.408354\n","(Epoch 13 / 15) train acc: 0.612000; val_acc: 0.536000\n","(Iteration 3201 / 3675) loss: 1.414654\n","(Iteration 3301 / 3675) loss: 1.530789\n","(Iteration 3401 / 3675) loss: 1.375997\n","(Epoch 14 / 15) train acc: 0.556000; val_acc: 0.539000\n","(Iteration 3501 / 3675) loss: 1.442351\n","(Iteration 3601 / 3675) loss: 1.349065\n","(Epoch 15 / 15) train acc: 0.610000; val_acc: 0.533000\n"]}],"source":["best_model_improved = None\n","\n","################################################################################\n","# TODO: Train the best FullyConnectedNetImproved that you can on CIFAR-10. You might   #\n","# find batch/layer normalization and dropout useful. Store your best model in  #\n","# the best_mode_improved variable.                                                     #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","lr = 0.00122810883630280872\n","reg = 0.0011124710979752646\n","weight_scale = 0.011387564370987585\n","dropout_keep_ratio = 0.9\n","H1, H2, H3 = 100, 50, 100\n","print(f\"lr: {lr}, reg: {reg}, weight_scale: {weight_scale}\")\n","net = FullyConnectedNetImproved(hidden_dims=[H1, H2, H3], dropout_keep_ratio=dropout_keep_ratio,\n","                                reg=reg ,weight_scale=weight_scale, dtype=np.float64,\n","                                normalization= 'layernorm')\n","\n","solver = Solver(net, data,\n","                    update_rule='adam',\n","                    optim_config={\n","                      'learning_rate': lr,\n","                    },\n","                    lr_decay=0.95,\n","                    num_epochs=15, batch_size=200, print_every=100,\n","                    verbose = True)\n","solver.train()\n","y_val_pred = np.argmax(net.loss(data['X_val']), axis=1)\n","val_acc = (y_val_pred == data['y_val']).mean()\n","best_model_improved = net\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"markdown","id":"63dfcffc","metadata":{"id":"63dfcffc"},"source":["# Test Your Model!\n","Run your best model on the validation and test sets. Are you able to outperform the baseline model that has no Batchnorm or Dropout?"]},{"cell_type":"code","execution_count":39,"id":"ff2b68c7","metadata":{"id":"ff2b68c7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731037255790,"user_tz":480,"elapsed":181,"user":{"displayName":"Hemkesh Bandi","userId":"14540947023276436947"}},"outputId":"639cd511-f6cb-49d4-b181-4087f6c22c9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation set accuracy:  0.539\n","Test set accuracy:  0.545\n"]}],"source":["y_test_pred = np.argmax(best_model_improved.loss(data['X_test']), axis=1)\n","y_val_pred = np.argmax(best_model_improved.loss(data['X_val']), axis=1)\n","print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n","print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}